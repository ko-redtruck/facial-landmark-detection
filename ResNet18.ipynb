{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import time\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.vision import StandardTransform\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = \"./data\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Instantiating CUDA device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"facial-keypoints-detection.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(f'{DATA_DIR}/training.zip')\n",
    "training_data = training_data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = [np.fromstring(image, dtype=np.uint8, sep=' ').reshape(96,96) for image in training_data[\"Image\"]]\n",
    "X = np.reshape(X,(-1,96, 96))\n",
    "Y = training_data[[\"left_eye_center_x\",\"left_eye_center_y\"]].values.reshape(-1,2).astype('float32')\n",
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for i in range(5):\n",
    "    plt.imshow(X[i], interpolation='nearest',cmap=\"gray\")\n",
    "    plt.plot(Y[i][0],Y[i][1],marker=\".\",color=\"red\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "X2 = []\n",
    "for i in range(len(X)):\n",
    "    img = Image.fromarray(X[i]).convert(\"RGB\")\n",
    "    img = preprocess(img)\n",
    "    X2.append(np.array(img))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y2 = Y * (224/96)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(X2[i].transpose(1,2,0), interpolation='nearest')\n",
    "    plt.plot(Y2[i][0],Y2[i][1],marker=\".\",color=\"red\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_Training = np.reshape(X2,(-1, 3, 224, 224))\n",
    "X_Training.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "\n",
    "net = tv.models.resnet18(pretrained=True)\n",
    "net.fc = nn.Linear(512,2)\n",
    "\n",
    "#Output final architecture\n",
    "net.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Define Loss\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#Define Optimizer(SGD)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "#worker-cores\n",
    "if sys.platform.startswith('win'):\n",
    "    num_workers = 0\n",
    "else:\n",
    "    num_workers = 4\n",
    "\n",
    "#batch-size\n",
    "batch_size = 40"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(list(zip(X_Training,Y2)), batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#Move the input and model to GPU for speed if available\n",
    "net.to(device)\n",
    "\n",
    "# Specify the number of epochs for training\n",
    "num_epochs = 2\n",
    "#Instatiate Logs\n",
    "running_loss_history = []\n",
    "running_corrects_history = []\n",
    "\n",
    "#Train the net\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    net.train()\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(inputs)\n",
    "        loss = loss_function(output,labels)\n",
    "        running_loss += loss\n",
    "\n",
    "        # setting initial parameter gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print(\"loss:\",loss.item())\n",
    "        #running_corrects += torch.sum(preds == labels.data) # calculating te accuracy by taking the sum of all the correct predictions in a batch.\n",
    "\n",
    "    epoch_loss = running_loss/len(trainloader) # loss per epoch\n",
    "    #epoch_acc = running_corrects.float()/ len(trainloader) # accuracy per epoch\n",
    "    running_loss_history.append(epoch_loss) # appending for displaying\n",
    "    #running_corrects_history.append(epoch_acc)\n",
    "    # net.eval()\n",
    "\n",
    "    print('Epoch:', epoch)\n",
    "    print('training loss: {:.4f}'.format(epoch_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}