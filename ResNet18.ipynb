{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import time\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.vision import StandardTransform\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = \"./data\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Instantiating CUDA device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"facial-keypoints-detection.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(f'{DATA_DIR}/training.zip')\n",
    "training_data = training_data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = [np.fromstring(image, dtype=np.uint8, sep=' ').reshape(96,96) for image in training_data[\"Image\"]]\n",
    "X = np.reshape(X,(-1,96, 96))\n",
    "Y = training_data[[\"left_eye_center_x\",\"left_eye_center_y\"]].values.reshape(-1,2).astype('float32')\n",
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for i in range(5):\n",
    "    plt.imshow(X[i], interpolation='nearest',cmap=\"gray\")\n",
    "    plt.plot(Y[i][0],Y[i][1],marker=\".\",color=\"red\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "X2 = []\n",
    "for i in range(len(X)):\n",
    "    img = Image.fromarray(X[i]).convert(\"RGB\")\n",
    "    img = preprocess(img)\n",
    "    X2.append(np.array(img))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y2 = Y * (224/96)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(X2[i].transpose(1,2,0), interpolation='nearest')\n",
    "    plt.plot(Y2[i][0],Y2[i][1],marker=\".\",color=\"red\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_Training = np.reshape(X2,(-1, 3, 224, 224))\n",
    "X_Training.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "\n",
    "net = tv.models.resnet18(pretrained=True)\n",
    "net.fc = nn.Linear(512,2)\n",
    "\n",
    "#Output final architecture\n",
    "net.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Define Loss\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#Define Optimizer(SGD)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "#worker-cores\n",
    "if sys.platform.startswith('win'):\n",
    "    num_workers = 0\n",
    "else:\n",
    "    num_workers = 4\n",
    "\n",
    "#batch-size\n",
    "batch_size = 40"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(list(zip(X_Training,Y2)), batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}