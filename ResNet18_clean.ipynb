{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Facial Landmark Detection - Intro to Deep Learning"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "40tVPVNIvSvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and Augment Data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AZ1Ngpc8vSvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": [
        "# General imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aVln6GB1vSvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download & Import Data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "S6Kj5uivvSvX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Download data from GitHub\n",
        "!pip install wget -qU\n",
        "import wget\n",
        "import os.path\n",
        "\n",
        "if not os.path.isfile(\"./facial-keypoints-detection.zip\"):\n",
        "    url = r\"https://github.com/ko-redtruck/facial-landmark-detection/raw/main/facial-keypoints-detection.zip\"\n",
        "    wget.download(url, \".\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6ZNte77vSvX",
        "outputId": "74bfe209-a176-4759-8e85-6ef89ca2d778"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Read training data\n",
        "import zipfile\n",
        "\n",
        "DATA_DIR = \"./data\"\n",
        "\n",
        "def load_data_and_filter_from(file: str):\n",
        "    data = pd.read_csv(f'{DATA_DIR}/{file}')\n",
        "    data = data.dropna()\n",
        "    return data\n",
        "\n",
        "with zipfile.ZipFile(\"./facial-keypoints-detection.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n",
        "\n",
        "training_data = load_data_and_filter_from('training.zip')\n",
        "# training_data"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E38koBEzvSvX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Convert data to numpy arrays\n",
        "\n",
        "def convert_to_numpy(data: pd.DataFrame):\n",
        "    X = [np.fromstring(image, dtype=np.uint8, sep=' ').reshape(96,96) for image in data[\"Image\"]]\n",
        "    X = np.reshape(X,(-1,96, 96))\n",
        "\n",
        "    Y = np.delete(data.values,30,axis=1)\n",
        "    Y = Y.reshape(-1,30).astype('float32')\n",
        "    return X,Y\n",
        "\n",
        "np_images, labels = convert_to_numpy(training_data)\n",
        "np_images.shape, labels.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pxKA1uuJvSvY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Plot images\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "def plot_image(image: Image, labeling: np.ndarray=None):\n",
        "    try:\n",
        "        image = to_pil_image(image)\n",
        "    finally:\n",
        "        plt.imshow(image, interpolation='nearest', cmap='gray')\n",
        "        if labeling is not None:\n",
        "            print(len(labeling))\n",
        "            for i in range(0, len(labeling)-1, 2):\n",
        "                plt.plot(labeling[i + 0],labeling[i + 1], marker=\".\", color='cyan')\n",
        "        plt.show()\n",
        "\n",
        "def plot_images(images: np.ndarray, labels: np.ndarray=None, num: int=None):\n",
        "    for i in range(num if num is not None else len(images)):\n",
        "        plot_image(images[i], labels[i])"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "L525SV-GvSvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plot_images(np_images, labels, 3)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "75H_WA_HvSvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image Preparation"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "K_U7B1dZvSva"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Transformation and augmentation of images\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as tf\n",
        "from numpy.random import randint, random\n",
        "\n",
        "def transform_image(image: np.ndarray):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ColorJitter(0.5, 0.5, 0.5, 0.5),\n",
        "        transforms.RandomErasing(scale=(0.01, 0.02))\n",
        "    ])\n",
        "\n",
        "    image = tf.to_tensor(image)\n",
        "    image = tf.adjust_sharpness(image, 2 * random())\n",
        "    return transform(image)\n",
        "\n",
        "def random_resize_datapoint(image: torch.Tensor, labeling: np.ndarray):\n",
        "    new_size = randint(image.shape[-1], 224, dtype='uint8')\n",
        "    scaling = new_size / image.shape[-1]\n",
        "\n",
        "    return tf.resize(image, [new_size, new_size]), labeling * scaling\n",
        "\n",
        "def augment_data(images, label_list, size_factor: int=1):\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for _ in range(size_factor):\n",
        "        for i in range(len(images)):\n",
        "            image = transform_image(images[i])\n",
        "            image, labeling = random_resize_datapoint(image, label_list[i])\n",
        "\n",
        "            augmented_images.append(image)\n",
        "            augmented_labels.append(labeling)\n",
        "\n",
        "    return augmented_images, augmented_labels"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cNpk_mJVvSva"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATASET_AUGMENTATION_FACTOR = 2\n",
        "\n",
        "augmented_images, augmented_labels = augment_data(np_images, labels, DATASET_AUGMENTATION_FACTOR)\n",
        "plot_images(augmented_images, augmented_labels, 3)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bA4s-RtLvSva"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Padding images\n",
        "from numpy.random import randint\n",
        "\n",
        "def random_pad_image_with_noise(image: torch.Tensor, new_size: (int, int), offset_x: int=0, offset_y: int=0):\n",
        "    random_image = tf.to_tensor(randint(256, dtype='uint8', size=new_size))\n",
        "\n",
        "    random_image[:, offset_y:image.shape[-2] + offset_y, offset_x:image.shape[-1] + offset_x] = image\n",
        "    return random_image\n",
        "\n",
        "def random_offset(image_dimensions, new_size: (int, int)):\n",
        "    min_offset = (0, 0)\n",
        "    max_offset = np.subtract(new_size, image_dimensions)\n",
        "\n",
        "    offset_y = randint(min_offset[0], max_offset[0])\n",
        "    offset_x = randint(min_offset[1], max_offset[1])\n",
        "    return offset_y, offset_x\n",
        "\n",
        "def random_pad_datapoint(image: torch.Tensor, labeling: np.ndarray, new_size: (int, int)):\n",
        "    offset_y, offset_x = random_offset(image.shape[-2:], new_size)\n",
        "\n",
        "    padded_image = random_pad_image_with_noise(image, new_size, offset_x=offset_x, offset_y=offset_y)\n",
        "    adjusted_labeling = np.zeros(labeling.shape, dtype=labeling.dtype)\n",
        "    adjusted_labeling[:-1:2] = labeling[:-1:2] + offset_x\n",
        "    adjusted_labeling[1::2] = labeling[1::2] + offset_y\n",
        "\n",
        "    return padded_image, adjusted_labeling\n",
        "\n",
        "def random_pad_data(images, labels, new_size: (int, int)):\n",
        "    padded_images = []\n",
        "    adjusted_labels = []\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        image, labeling = random_pad_datapoint(image=images[i], labeling=labels[i], new_size=new_size)\n",
        "        padded_images.append(image)\n",
        "        adjusted_labels.append(labeling)\n",
        "\n",
        "    return padded_images, adjusted_labels"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YPCCjMSHvSva"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "padded_images, final_labels = random_pad_data(augmented_images, augmented_labels, (224, 224))\n",
        "plot_images(padded_images, final_labels, 3)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dl8wXIvQvSvb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Transform images to RGB\n",
        "final_images = torch.zeros((len(padded_images), 3, 224, 224))\n",
        "final_images[:, :] = padded_images[:][0]\n",
        "final_images.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RdzInWH7vSvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "#### Set up wandb & Cuda device"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aa99Ybq3vSvc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#Instantiating CUDA device\n",
        "import torch\n",
        "\n",
        "def device():\n",
        "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ro2Tc_txvSvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "VgVu8aGjCrEp",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define model and parameters for run"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "2H_CF10cvSvc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "NET = \"ResNet18\"\n",
        "FC_LAYER = \"Lin-ReLu-Lin\"\n",
        "OPTIMIZER = \"Adam\"\n",
        "LOSS = \"MSE\"\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 400\n",
        "LR = 0.001\n",
        "MOMENTUM = 0.9 # SGD\n",
        "WEIGHT_DECAY = 0.01"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wZhGsTvlvSvc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Define parameter mappings\n",
        "from torchvision.models import resnet18\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "\n",
        "def add_fc(net, layer):\n",
        "    net.fc = layer\n",
        "    return net\n",
        "\n",
        "fc_layers = {\n",
        "    \"Lin-ReLu-Lin\": nn.Sequential(\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,30)\n",
        "    ),\n",
        "    \"Linear\": nn.Linear(512, 30)\n",
        "}\n",
        "\n",
        "networks = {\n",
        "    \"ResNet18\": add_fc(resnet18(pretrained=True), fc_layers[FC_LAYER])\n",
        "}\n",
        "\n",
        "optimizers = {\n",
        "    \"Adam\": Adam(networks[NET].parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "}\n",
        "\n",
        "loss_functions = {\n",
        "    \"MSE\": nn.MSELoss()\n",
        "}"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ql_RSVLlvSvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set up Training"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5ais4sxtvSvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "net = networks[NET].to(device())\n",
        "optimizer = optimizers[OPTIMIZER]\n",
        "loss_function = loss_functions[LOSS]\n",
        "num_workers = 0 if sys.platform.startswith('win') else 2"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HLEyGqG2vSvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Define data loaders\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "def get_data_loaders(images, labels, batch_size, test_data_split=0.1, num_workers=2):\n",
        "    dataset = list(zip(images, labels))\n",
        "    training_data_size = int(len(dataset) * (1-test_data_split))\n",
        "    train, test = random_split(dataset, [training_data_size, len(dataset) - training_data_size])\n",
        "\n",
        "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    test_loader = DataLoader(test, batch_size=batch_size, num_workers=num_workers)\n",
        "    return train_loader,test_loader"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TgpJilcRvSvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_loader, test_loader = get_data_loaders(final_images, final_labels, batch_size=BATCH_SIZE, test_data_split=0.15, num_workers=num_workers)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SHaqXDYJvSvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VKns9hqXvSve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Define training and testing steps\n",
        "\n",
        "def compute_loss(inputs, labels, net, loss_function):\n",
        "    outputs = net(inputs.to(device()))\n",
        "    labels = labels.to(device())\n",
        "\n",
        "    return loss_function(outputs, labels)\n",
        "\n",
        "def evaluate_model_on_dataset(net, loss_function, data_loader, optimize_weights=None):\n",
        "    avg_loss = 0.\n",
        "\n",
        "    for images, labels in data_loader:\n",
        "        loss = compute_loss(images, labels, net, loss_function)\n",
        "        avg_loss += loss\n",
        "\n",
        "        if optimize_weights is not None:\n",
        "            optimize_weights(loss)\n",
        "\n",
        "    return avg_loss / len(data_loader)\n",
        "\n",
        "def optimize_weights(optimizer):\n",
        "    def optimize_weights(loss):\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return optimize_weights"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "S8Me7fK4vSve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Init wandb tracking\n",
        "wandb.init(project=\"facial-landmark-detection\", entity=\"leo-team\", config={\"net\": NET, \"optimizer\": OPTIMIZER, \"final_layer\": FC_LAYER, \"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE, \"lr\": LR, \"momentum\": MOMENTUM, \"weight decay\" : WEIGHT_DECAY, \"\" : DATASET_AUGMENTATION_FACTOR})\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(EPOCHS): # loop over dataset several times\n",
        "    net.train()\n",
        "    train_loss = evaluate_model_on_dataset(net, loss_function, train_loader, optimize_weights(optimizer))\n",
        "\n",
        "    net.eval()\n",
        "    test_loss = evaluate_model_on_dataset(net, loss_function, test_loader)\n",
        "\n",
        "    # log error\n",
        "    print('epoch {}, train loss {}, test loss {}'.format(epoch+1, train_loss, test_loss))\n",
        "    wandb.log({\n",
        "        \"train_loss\": train_loss,\n",
        "        \"test_loss\": test_loss,\n",
        "    })"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "DU93CWIjvSve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "atE3udcRvSve"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "ResNet18_clean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}